{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1GhO8Nx22gW1t-cL9NZnp_rNiIURNdbqj",
      "authorship_tag": "ABX9TyNKknPJUesvuqptNfP47Flx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fazal735/DL_A2/blob/main/DL_A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "gH4UR8swGpVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "F9B_ez4BtbKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading data from Kaggle to reduce the jargan of loading the data to gdrive and then loading or this ipynb\n",
        "train_data_dir = '/kaggle/input/nature-12k/inaturalist_12K/train'\n",
        "test_data_dir = '/kaggle/input/nature-12k/inaturalist_12K/val'\n"
      ],
      "metadata": {
        "id": "-7pou-cN_xvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model definition"
      ],
      "metadata": {
        "id": "4CJKcqO-0Ku_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rn01KxwgGnYh"
      },
      "outputs": [],
      "source": [
        "# model definetion\n",
        "class model(nn.Module):\n",
        "  def __init__(self,num_filters=[32,64,128,256,512],filter_size=[3,3,5,5,7],activation=nn.ReLU(),\n",
        "               stride=1, padding=1, pool_size=(2,2),fc_size=512,nom_o_classes=10,\n",
        "               dropout=0,inchannels=3):\n",
        "    super(model,self).__init__()\n",
        "    self.num_filters=num_filters\n",
        "    self.filter_size=filter_size\n",
        "    self.activation=activation\n",
        "    self.stride=stride\n",
        "    self.padding=padding\n",
        "    self.pool_size=pool_size\n",
        "    self.fc_size=fc_size\n",
        "    self.nom_o_classes=nom_o_classes\n",
        "    self.dropout=dropout\n",
        "    self.channels=inchannels\n",
        "\n",
        "\n",
        "    def image_size(img_w,filter_size,padding,stride):\n",
        "      return ((img_w-filter_size+2*padding)/stride+1)*0.5\n",
        "\n",
        "\n",
        "    #layers of convolution\n",
        "    #layer1\n",
        "    self.conv_layer1=nn.Conv2d(self.channels,self.num_filters[0], stride=self.stride, padding=self.padding,\n",
        "                               kernel_size=self.filter_size[0])\n",
        "    self.dropout1=nn.Dropout2d(self.dropout)\n",
        "    self.batch_norm1=nn.BatchNorm2d(self.num_filters[0])\n",
        "    img_size1=image_size(224,self.filter_size[0],self.padding,self.stride)\n",
        "\n",
        "    #layer2\n",
        "    self.conv_layer2=nn.Conv2d(self.channels,self.num_filters[1], stride=self.stride, padding=self.padding,\n",
        "                              kernel_size=self.filter_size[1])\n",
        "    self.dropout2=nn.Dropout2d(self.dropout)\n",
        "    self.batch_norm2=nn.BatchNorm2d(self.num_filters[1])\n",
        "    img_size2=image_size(img_size1,self.filter_size[1],self.padding,self.stride)\n",
        "\n",
        "    #layer3\n",
        "    self.conv_layer3=nn.Conv2d(self.channels,self.num_filters[2], stride=self.stride, padding=self.padding,\n",
        "                              kernel_size=self.filter_size[2])\n",
        "    self.dropout3=nn.Dropout2d(self.dropout)\n",
        "    self.batch_norm3=nn.BatchNorm2d(self.num_filters[2])\n",
        "    img_size3=image_size(img_size2,self.filter_size[2],self.padding,self.stride)\n",
        "\n",
        "    #layer4\n",
        "    self.conv_layer4=nn.Conv2d(self.channels,self.num_filters[3], stride=self.stride, padding=self.padding,\n",
        "                              kernel_size=self.filter_size[3])\n",
        "    self.dropout4=nn.Dropout2d(self.dropout)\n",
        "    self.batch_norm4=nn.BatchNorm2d(self.num_filters[3])\n",
        "    img_size4=image_size(img_size3,self.filter_size[3],self.padding,self.stride)\n",
        "\n",
        "    #layer5\n",
        "    self.conv_layer5=nn.Conv2d(self.channels,self.num_filters[4], stride=self.stride, padding=self.padding,\n",
        "                              kernel_size=self.filter_size[4])\n",
        "    self.dropout5=nn.Dropout2d(self.dropout)\n",
        "    self.batch_norm5=nn.BatchNorm2d(self.num_filters[4])\n",
        "    img_size5=int(image_size(img_size4,self.filter_size[4],self.padding,self.stride))\n",
        "\n",
        "\n",
        "    self.pool=nn.MaxPool2d(self.pool_size,stride=2)\n",
        "\n",
        "\n",
        "\n",
        "    # forward\n",
        "  def forward(self,x):\n",
        "    #layer1\n",
        "    x=self.conv_layer1(x)\n",
        "    x=self.activation(x)\n",
        "    x=self.pool(x)\n",
        "    x=self.dropout1(x)\n",
        "    x=self.batch_norm1(x)\n",
        "\n",
        "      #layer2\n",
        "    x=self.conv_layer2(x)\n",
        "    x=self.activation(x)\n",
        "    x=self.pool(x)\n",
        "    x=self.dropout2(x)\n",
        "    x=self.batch_norm2(x)\n",
        "\n",
        "    #layer3\n",
        "    x=self.conv_layer3(x)\n",
        "    x=self.activation(x)\n",
        "    x=self.pool(x)\n",
        "    x=self.dropout3(x)\n",
        "    x=self.batch_norm3(x)\n",
        "\n",
        "    #layer4\n",
        "    x=self.conv_layer4(x)\n",
        "    x=self.activation(x)\n",
        "    x=self.pool(x)\n",
        "    x=self.dropout4(x)\n",
        "    x=self.batch_norm4(x)\n",
        "\n",
        "    #layer5\n",
        "    x=self.conv_layer5(x)\n",
        "    x=self.activation(x)\n",
        "    x=self.pool(x)\n",
        "    x=self.dropout5(x)\n",
        "    x=self.batch_norm5(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=100\n",
        "learning_rate=0.1"
      ],
      "metadata": {
        "id": "ZOrkblSLG7sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=model()\n",
        "loss=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "HgtPlp5vHG73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model training function"
      ],
      "metadata": {
        "id": "FAJDHetA0Akv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training(model,data):\n",
        "  loss_metric=nn.CrossEntropyLoss()\n",
        "  optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "\n",
        "  model.train()\n",
        "  training_loss=0.0\n",
        "  true_label=0\n",
        "  total_train=0\n",
        "\n",
        "  for input, label in data:\n",
        "    optimizer.zero_grad()\n",
        "    output=model(input)\n",
        "    loss=loss_metric(output,label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    trainning_loss+=loss.item()\n",
        "    _,predicted=torch.max(output.data,1)\n",
        "    total_train+=label.size(0)\n",
        "    true_label+=(predicted==label).sum().item()\n",
        "\n",
        "  train_accuracy=100*true_label/total_train\n",
        "  return train_accuracy,training_loss.model\n"
      ],
      "metadata": {
        "id": "JSNnQI40HJI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model testing function(on validation data)"
      ],
      "metadata": {
        "id": "p2agnKN30E54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_on_valid_data(model, test_data):\n",
        "    model.eval()\n",
        "    correct_label = 0\n",
        "    total_label = 0\n",
        "    with torch.no_grad():\n",
        "        for img, label in test_data:\n",
        "            img, label = img.to(device), label.to(device)\n",
        "            output = model(img)\n",
        "\n",
        "            _, pred = torch.max(output, 1)\n",
        "            correct_label += (pred == label).sum().item()\n",
        "            total_label += label.size(0)\n",
        "\n",
        "    valid_accuracy = 100 * correct_label / total_label\n",
        "    return valid_accuracy\n"
      ],
      "metadata": {
        "id": "LtXvXgFRx4o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_train_val(model, train_data, val_data,epochs):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model, avg_loss, train_accuracy = training(model, train_data)\n",
        "        # Print training loss and accuracy\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "        # Validation loop\n",
        "        val_accuracy = test_on_valid_data(model, val_data)\n",
        "        # Print validation accuracy\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Validation Accuracy: {val_accuracy:.2f}%')\n"
      ],
      "metadata": {
        "id": "LnUsHUP-6Aru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cb7rR72xABts"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}