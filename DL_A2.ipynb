{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1GhO8Nx22gW1t-cL9NZnp_rNiIURNdbqj",
      "authorship_tag": "ABX9TyN0XgALe51xCGF4WYOY6Hgd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fazal735/DL_A2/blob/main/DL_A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "gH4UR8swGpVy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1paXXbIlSau",
        "outputId": "9c5ef1fd-f02e-464a-dd4c-9a880e20ce87"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_file='/content/drive/MyDrive/inaturalist_12K/train'\n",
        "test_file='/content/drive/MyDrive/inaturalist_12K/val'"
      ],
      "metadata": {
        "id": "0QDe3Fmsli4Y"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "MyH0mjUlsvmW",
        "outputId": "c8bb8e02-02c3-4dde-f21e-fdcf67e8148f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Aves' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-10eb1fd77cdc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_file\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mAves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Aves' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fazal735/DL_A2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6dlPviclzWm",
        "outputId": "912bfd4c-270e-4f1f-8696-e65b73ebe8a5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DL_A2'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn01KxwgGnYh",
        "outputId": "e3c2807d-3ba7-4fcf-983d-d1403cb08311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model(\n",
            "  (activation): ReLU()\n",
            "  (conv_layer1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (dropout1): Dropout2d(p=0, inplace=False)\n",
            "  (batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_layer2): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (dropout2): Dropout2d(p=0, inplace=False)\n",
            "  (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_layer3): Conv2d(3, 128, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "  (dropout3): Dropout2d(p=0, inplace=False)\n",
            "  (batch_norm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_layer4): Conv2d(3, 256, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "  (dropout4): Dropout2d(p=0, inplace=False)\n",
            "  (batch_norm4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_layer5): Conv2d(3, 512, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
            "  (dropout5): Dropout2d(p=0, inplace=False)\n",
            "  (batch_norm5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (pool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# model definetion\n",
        "class model(nn.Module):\n",
        "  def __init__(self,num_filters=[32,64,128,256,512],filter_size=[3,3,5,5,7],activation=nn.ReLU(),\n",
        "               stride=1, padding=1, pool_size=(2,2),fc_size=512,nom_o_classes=10,\n",
        "               dropout=0,inchannels=3):\n",
        "    super(model,self).__init__()\n",
        "    self.num_filters=num_filters\n",
        "    self.filter_size=filter_size\n",
        "    self.activation=activation\n",
        "    self.stride=stride\n",
        "    self.padding=padding\n",
        "    self.pool_size=pool_size\n",
        "    self.fc_size=fc_size\n",
        "    self.nom_o_classes=nom_o_classes\n",
        "    self.dropout=dropout\n",
        "    self.channels=inchannels\n",
        "\n",
        "\n",
        "    def image_size(img_w,filter_size,padding,stride):\n",
        "      return ((img_w-filter_size+2*padding)/stride+1)*0.5\n",
        "\n",
        "\n",
        "    #layers of convolution\n",
        "    #layer1\n",
        "    self.conv_layer1=nn.Conv2d(self.channels,self.num_filters[0], stride=self.stride, padding=self.padding,\n",
        "                               kernel_size=self.filter_size[0])\n",
        "    self.dropout1=nn.Dropout2d(self.dropout)\n",
        "    self.batch_norm1=nn.BatchNorm2d(self.num_filters[0])\n",
        "    img_size1=image_size(224,self.filter_size[0],self.padding,self.stride)\n",
        "\n",
        "    #layer2\n",
        "    self.conv_layer2=nn.Conv2d(self.channels,self.num_filters[1], stride=self.stride, padding=self.padding,\n",
        "                              kernel_size=self.filter_size[1])\n",
        "    self.dropout2=nn.Dropout2d(self.dropout)\n",
        "    self.batch_norm2=nn.BatchNorm2d(self.num_filters[1])\n",
        "    img_size2=image_size(img_size1,self.filter_size[1],self.padding,self.stride)\n",
        "\n",
        "    #layer3\n",
        "    self.conv_layer3=nn.Conv2d(self.channels,self.num_filters[2], stride=self.stride, padding=self.padding,\n",
        "                              kernel_size=self.filter_size[2])\n",
        "    self.dropout3=nn.Dropout2d(self.dropout)\n",
        "    self.batch_norm3=nn.BatchNorm2d(self.num_filters[2])\n",
        "    img_size3=image_size(img_size2,self.filter_size[2],self.padding,self.stride)\n",
        "\n",
        "    #layer4\n",
        "    self.conv_layer4=nn.Conv2d(self.channels,self.num_filters[3], stride=self.stride, padding=self.padding,\n",
        "                              kernel_size=self.filter_size[3])\n",
        "    self.dropout4=nn.Dropout2d(self.dropout)\n",
        "    self.batch_norm4=nn.BatchNorm2d(self.num_filters[3])\n",
        "    img_size4=image_size(img_size3,self.filter_size[3],self.padding,self.stride)\n",
        "\n",
        "    #layer5\n",
        "    self.conv_layer5=nn.Conv2d(self.channels,self.num_filters[4], stride=self.stride, padding=self.padding,\n",
        "                              kernel_size=self.filter_size[4])\n",
        "    self.dropout5=nn.Dropout2d(self.dropout)\n",
        "    self.batch_norm5=nn.BatchNorm2d(self.num_filters[4])\n",
        "    img_size5=int(image_size(img_size4,self.filter_size[4],self.padding,self.stride))\n",
        "\n",
        "\n",
        "    self.pool=nn.MaxPool2d(self.pool_size,stride=2)\n",
        "\n",
        "\n",
        "\n",
        "    # forward\n",
        "    def forward(self,x):\n",
        "      #layer1\n",
        "      x=self.conv_layer0(x)\n",
        "      x=self.activation(x)\n",
        "      x=self.pool(x)\n",
        "\n",
        "      #layer2\n",
        "      x=self.conv_layer1(x)\n",
        "      x=self.activation(x)\n",
        "      x=self.pool(x)\n",
        "\n",
        "      #layer3\n",
        "      x=self.conv_layer2(x)\n",
        "      x=self.activation(x)\n",
        "      x=self.pool(x)\n",
        "\n",
        "      #layer4\n",
        "      x=self.conv_layer3(x)\n",
        "      x=self.activation(x)\n",
        "      x=self.pool(x)\n",
        "\n",
        "      #layer5\n",
        "      x=self.conv_layer4(x)\n",
        "      x=self.activation(x)\n",
        "      x=self.pool(x)\n",
        "\n",
        "      self.classifier=nn.Sequential(nn.Flatten(),nn.Linear('''tensor size'''),nn.ReLU(),\n",
        "                                    nn.Linear(),nn.ReLU(),\n",
        "                                    nn.Linear()\n",
        "                                    )\n",
        "\n",
        "\n",
        "\n",
        "model=model()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=100\n",
        "learning_rate=0.1"
      ],
      "metadata": {
        "id": "ZOrkblSLG7sz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)"
      ],
      "metadata": {
        "id": "HgtPlp5vHG73"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  #fo\n",
        "\n",
        "    #forwards pass\n",
        "\n",
        "    #loss calculation\n",
        "\n",
        "    # back porp\n",
        "\n",
        "    #update grads"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "JSNnQI40HJI0",
        "outputId": "cab28839-5af5-4cc1-e02b-bfdb31266fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-6-b1da103691c9>, line 13)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-b1da103691c9>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    #update grads\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_model(nn.Module):\n",
        "  def __init__(self, input_features, num_filters=[32,64,128,256,512],filter_size=[3,3,5,5,7],activation=nn.ReLU(),\n",
        "               stride=1, padding=1, pool_size=(2,2),fc_size=512,nom_o_classes=10,\n",
        "               dropout=0,inchannels=3):\n",
        "    super().__init__()\n",
        "\n",
        "    self.features=nn.Sequential(\n",
        "        nn.Conv2d(input_features,in_channels=3, num_filters[0], kernel_size=filter_size[0],stride=stride,padding=padding),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2)\n",
        "    )\n",
        "\n",
        "    self.classifier=nn.Sequential()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x=self.features(x)\n",
        "    x=self.classifier(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "9H35fbUmHLHi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "d30f0ac3-f2c5-4e57-8138-aac6ea39bc9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "positional argument follows keyword argument (<ipython-input-14-6300cac1d05e>, line 8)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-6300cac1d05e>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    nn.Conv2d(input_features,in_channels=3, num_filters[0], kernel_size=filter_size[0],stride=stride,padding=padding),\u001b[0m\n\u001b[0m                                                                                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision import datasets,transforms\n",
        "\n",
        "data=datasets.ImageFolder(root='/content/drive/MyDrive/inaturalist_12K/train/Amphibia',transform=transforms.ToTensor())\n"
      ],
      "metadata": {
        "id": "fRPSFH7Z8GlW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "fa071368-c491-48f0-9bab-37568a59382b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Couldn't find any class folder in /content/drive/MyDrive/inaturalist_12K/train/Amphibia.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-a3341f2f569f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/inaturalist_12K/train/Amphibia'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    147\u001b[0m     ) -> None:\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         samples = self.make_dataset(\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in /content/drive/MyDrive/inaturalist_12K/train/Amphibia."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cb7rR72xABts"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}