{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fazal735/DL_A2/blob/main/DL_A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gH4UR8swGpVy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader,SubsetRandomSampler\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyAQJsl3nQpL",
        "outputId": "5907d187-a100-442d-b6f8-9d6b2ab50857"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = '/content/drive/MyDrive/inaturalist_12K/train'\n",
        "test_data_dir = '/content/drive/MyDrive/inaturalist_12K/val'"
      ],
      "metadata": {
        "id": "38ChQLPx-Kta"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "F9B_ez4BtbKJ"
      },
      "outputs": [],
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-7pou-cN_xvq"
      },
      "outputs": [],
      "source": [
        "\n",
        "# train data loading\n",
        "def train_data(train_data_dir,data_augmentation):\n",
        "  size=transforms.Resize((224,224))\n",
        "  to_tensor=transforms.ToTensor()\n",
        "  #check again-autogenerated\n",
        "  normalize=transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])\n",
        "  crop=transforms.RandomResizedCrop(224)\n",
        "  flip=transforms.RandomHorizontalFlip()\n",
        "  #try changing the values\n",
        "  color=transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
        "  rotation=transforms.RandomRotation(30)\n",
        "\n",
        "\n",
        "  #augmentation of image\n",
        "  if data_augmentation == 'Yes':\n",
        "        transform_img = transforms.Compose([crop,flip,color, rotation, to_tensor,normalize]) # Data transformations\n",
        "\n",
        "  else:\n",
        "      transform_img = transforms.Compose([size,to_tensor, normalize ])\n",
        "\n",
        "\n",
        "\n",
        "  #data fetchiing\n",
        "  training_data=torchvision.datasets.ImageFolder(train_data_dir, transform=transform_img)\n",
        "\n",
        "\n",
        "  train_index, val_index = train_test_split(list(range(len(training_data))), test_size=0.2, random_state=42)\n",
        "  train_sampler = SubsetRandomSampler(train_index)\n",
        "  val_sampler = SubsetRandomSampler(val_index)\n",
        "\n",
        "  train_data=DataLoader(training_data,batch_size=32,sampler=train_sampler)\n",
        "  validation_data = DataLoader(training_data, batch_size=32, sampler=val_sampler)\n",
        "\n",
        "\n",
        "  return train_data,validation_data\n",
        "\n",
        "#test data loading\n",
        "def test_data(test_data_dir,data_augmentation):\n",
        "  size=transforms.Resize((224,224))\n",
        "  to_tensor=transforms.ToTensor()\n",
        "  #check again-autogenerated\n",
        "  normalize=transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])\n",
        "  crop=transforms.RandomResizedCrop(224)\n",
        "  flip=transforms.RandomHorizontalFlip()\n",
        "  #try changing the values\n",
        "  color=transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)\n",
        "  rotation=transforms.RandomRotation(30)\n",
        "\n",
        "  #augmentation of image\n",
        "  data_augmentation=transforms.Compose([size,to_tensor,normalize,crop,flip,color,rotation])\n",
        "\n",
        "  #data fetching\n",
        "  test_data=torchvision.datasets.ImageFolder(test_data_dir)\n",
        "  test_data=DataLoader(test_data,batch_size=32)\n",
        "  print(test_data.type)\n",
        "\n",
        "  return test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CJKcqO-0Ku_"
      },
      "source": [
        "model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Rn01KxwgGnYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc0056a5-4442-489b-ebc5-2060bb08a2d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model(\n",
            "  (activation): ReLU()\n",
            "  (conv_layer1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (batch_norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout1): Dropout2d(p=0, inplace=False)\n",
            "  (conv_layer2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (batch_norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout2): Dropout2d(p=0, inplace=False)\n",
            "  (conv_layer3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "  (batch_norm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout3): Dropout2d(p=0, inplace=False)\n",
            "  (conv_layer4): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "  (batch_norm4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout4): Dropout2d(p=0, inplace=False)\n",
            "  (conv_layer5): Conv2d(256, 512, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
            "  (batch_norm5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout5): Dropout2d(p=0, inplace=False)\n",
            "  (pool): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout_layer): Dropout1d(p=0, inplace=False)\n",
            "  (fc): Linear(in_features=8192, out_features=512, bias=True)\n",
            "  (fc_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (output_layer): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "evice, but foun# model definetion\n",
        "class model(nn.Module):\n",
        "  def __init__(self,num_filters=[32,64,128,256,512],filter_size=[3,3,5,5,7],activation=nn.ReLU(),\n",
        "               stride=1, padding=1, pool_size=(2,2),fc_size=512,nom_o_classes=10,\n",
        "               dropout=0,in_channels=3,batch_norm='YES'):\n",
        "    super(model,self).__init__()\n",
        "    self.num_filters=num_filters\n",
        "    self.filter_size=filter_size\n",
        "    self.activation=activation\n",
        "    self.stride=stride\n",
        "    self.padding=padding\n",
        "    self.pool_size=pool_size\n",
        "    self.fc_size=fc_size\n",
        "    self.nom_o_classes=nom_o_classes\n",
        "    self.dropout=dropout\n",
        "    self.channels=in_channels\n",
        "\n",
        "\n",
        "    def image_size(img_w,filter_size,padding,stride):\n",
        "      return ((img_w-filter_size+2*padding)/stride+1)*0.5\n",
        "\n",
        "\n",
        "    #layers of convolution\n",
        "    #layer1\n",
        "    self.conv_layer1=nn.Conv2d(self.channels,self.num_filters[0], stride=self.stride, padding=self.padding,\n",
        "                               kernel_size=self.filter_size[0])\n",
        "    self.batch_norm1=nn.BatchNorm2d(self.num_filters[0])\n",
        "    self.dropout1=nn.Dropout2d(self.dropout)\n",
        "\n",
        "    img_size1=image_size(224,self.filter_size[0],self.padding,self.stride)\n",
        "\n",
        "    #layer2\n",
        "    self.conv_layer2=nn.Conv2d(self.num_filters[0],self.num_filters[1], stride=self.stride, padding=self.padding,\n",
        "                              kernel_size=self.filter_size[1])\n",
        "    self.batch_norm2=nn.BatchNorm2d(self.num_filters[1])\n",
        "    self.dropout2=nn.Dropout2d(self.dropout)\n",
        "\n",
        "    img_size2=image_size(img_size1,self.filter_size[1],self.padding,self.stride)\n",
        "\n",
        "    #layer3\n",
        "    self.conv_layer3=nn.Conv2d(self.num_filters[1],self.num_filters[2], stride=self.stride, padding=self.padding,\n",
        "                              kernel_size=self.filter_size[2])\n",
        "    self.batch_norm3=nn.BatchNorm2d(self.num_filters[2])\n",
        "    self.dropout3=nn.Dropout2d(self.dropout)\n",
        "\n",
        "    img_size3=image_size(img_size2,self.filter_size[2],self.padding,self.stride)\n",
        "\n",
        "    #layer4\n",
        "    self.conv_layer4=nn.Conv2d(self.num_filters[2],self.num_filters[3], stride=self.stride, padding=self.padding,\n",
        "                              kernel_size=self.filter_size[3])\n",
        "    self.batch_norm4=nn.BatchNorm2d(self.num_filters[3])\n",
        "    self.dropout4=nn.Dropout2d(self.dropout)\n",
        "\n",
        "    img_size4=image_size(img_size3,self.filter_size[3],self.padding,self.stride)\n",
        "\n",
        "    #layer5\n",
        "    self.conv_layer5=nn.Conv2d(self.num_filters[3],self.num_filters[4], stride=self.stride, padding=self.padding,\n",
        "                              kernel_size=self.filter_size[4])\n",
        "    self.batch_norm5=nn.BatchNorm2d(self.num_filters[4])\n",
        "    self.dropout5=nn.Dropout2d(self.dropout)\n",
        "\n",
        "    img_size5=int(image_size(img_size4,self.filter_size[4],self.padding,self.stride))\n",
        "\n",
        "\n",
        "    self.pool=nn.MaxPool2d(self.pool_size,stride=2)\n",
        "\n",
        "    self.dropout_layer = nn.Dropout1d(self.dropout)\n",
        "\n",
        "    # Define fully connected layer\n",
        "    self.fc = nn.Linear(self.num_filters[4] * (img_size5 ** 2), self.fc_size)\n",
        "    self.fc_bn = nn.BatchNorm1d(self.fc_size)  # Batch normalization for fully connected layer\n",
        "\n",
        "    # Output layer\n",
        "    self.output_layer = nn.Linear(self.fc_size, self.nom_o_classes)\n",
        "\n",
        "    # forward\n",
        "  def forward(self,x):\n",
        "    #layer1\n",
        "    x=self.conv_layer1(x)\n",
        "    x=self.activation(x)\n",
        "    x=self.pool(x)\n",
        "    x=self.dropout1(x)\n",
        "    x=self.batch_norm1(x)\n",
        "\n",
        "      #layer2\n",
        "    x=self.conv_layer2(x)\n",
        "    x=self.activation(x)\n",
        "    x=self.pool(x)\n",
        "    x=self.dropout2(x)\n",
        "    x=self.batch_norm2(x)\n",
        "\n",
        "    #layer3\n",
        "    x=self.conv_layer3(x)\n",
        "    x=self.activation(x)\n",
        "    x=self.pool(x)\n",
        "    x=self.dropout3(x)\n",
        "    x=self.batch_norm3(x)\n",
        "\n",
        "    #layer4\n",
        "    x=self.conv_layer4(x)\n",
        "    x=self.activation(x)\n",
        "    x=self.pool(x)\n",
        "    x=self.dropout4(x)\n",
        "    x=self.batch_norm4(x)\n",
        "\n",
        "    #layer5\n",
        "    x=self.conv_layer5(x)\n",
        "    x=self.activation(x)\n",
        "    x=self.pool(x)\n",
        "    x=self.dropout5(x)\n",
        "    x=self.batch_norm5(x)\n",
        "\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc(x)\n",
        "    x = self.fc_bn(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.dropout_layer(x)\n",
        "    x = self.output_layer(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "model1=model()\n",
        "print(model1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZOrkblSLG7sz"
      },
      "outputs": [],
      "source": [
        "epochs=100\n",
        "learning_rate=0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "HgtPlp5vHG73"
      },
      "outputs": [],
      "source": [
        "\n",
        "loss=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.SGD(model1.parameters(),lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAJDHetA0Akv"
      },
      "source": [
        "model training function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "JSNnQI40HJI0"
      },
      "outputs": [],
      "source": [
        "def training(model1,data):\n",
        "  loss_metric=nn.CrossEntropyLoss()\n",
        "  optimizer=torch.optim.SGD(model1.parameters(),lr=learning_rate)\n",
        "\n",
        "  model1.train()\n",
        "  training_loss=0.0\n",
        "  true_label=0\n",
        "  total_train=0\n",
        "\n",
        "  for input, label in data:\n",
        "\n",
        "\n",
        "    input = input.to(device)\n",
        "    model1 = model1.to(device)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output=model1(input)\n",
        "    loss=loss_metric(output,label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    training_loss += loss.item()\n",
        "    _,predicted=torch.max(output.data,1)\n",
        "    total_train += label.size(0)\n",
        "    true_label += (predicted==label).sum().item()\n",
        "\n",
        "  train_accuracy=100*true_label/total_train\n",
        "  return train_accuracy,training_loss,model1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2agnKN30E54"
      },
      "source": [
        "model testing function(on validation data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "LtXvXgFRx4o5"
      },
      "outputs": [],
      "source": [
        "def test_on_valid_data(model, test_data):\n",
        "    model.eval()\n",
        "\n",
        "    correct_label = 0\n",
        "    total_label = 0\n",
        "    with torch.no_grad():\n",
        "        for img, label in test_data:\n",
        "            img, label = img.to(device), label.to(device)\n",
        "            output = model(img)\n",
        "\n",
        "            _, pred = torch.max(output, 1)\n",
        "            correct_label += (pred == label).sum().item()\n",
        "            total_label += label.size(0)\n",
        "\n",
        "    valid_accuracy = 100 * correct_label / total_label\n",
        "    return valid_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LnUsHUP-6Aru"
      },
      "outputs": [],
      "source": [
        "def model_train_val(model, train_data, val_data,epochs):\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_accuracy,avg_loss,model1 = training(model, train_data)\n",
        "        # Print training loss and accuracy\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "        # Validation loop\n",
        "        val_accuracy = test_on_valid_data(model, val_data)\n",
        "        # Print validation accuracy\n",
        "        print(f'Epoch {epoch+1}/{epochs}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "\n",
        "        wandb.log({'Train loss': avg_loss})\n",
        "        wandb.log({'Train accuracy': train_accuracy})\n",
        "\n",
        "        wandb.log({'val_accuracy': val_accuracy})\n",
        "        wandb.log({'epoch': epoch})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb7rR72xABts",
        "outputId": "6adaa26e-b6c0-452e-e0d1-7519c67d1e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.25.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "e4d0a8c3ccaf2534e9ab91c659e420ba5114533f\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "BKO6dIE-q2Oy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlwujivySuZk",
        "outputId": "9839ee52-0c8f-4c73-d58e-7eb96cea2756"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwKIfz6h8Gx1",
        "outputId": "43dd2a9b-a3b6-4d22-dae4-092933d7296b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: al6ebpim\n",
            "Sweep URL: https://wandb.ai/mfazal735-iit-madras-foundation/DL%20A2/sweeps/al6ebpim\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'kernel_size':{\n",
        "            'values': [[3,3,3,3,3],[3,5,5,7,7],[3,5,3,5,7],[5,5,5,5,5]]#,[7,7,7,7,7]]\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0.3, 0.2]\n",
        "        },\n",
        "        'activation': {\n",
        "            'values': [ 'relu','mish','silu', 'gelu',]\n",
        "        },\n",
        "        'num_dense':{\n",
        "            'values': [128, 256]\n",
        "        },\n",
        "        'batch_norm':{\n",
        "            'values': ['Yes','No']\n",
        "        },\n",
        "        'filter_org':{\n",
        "            'values': [[128,128,64,64,32],[32,64,128,256,512],[32,32,32,32,32],[32,64,64,128,128]]\n",
        "        },\n",
        "        'learning_rate':{\n",
        "            'values': [0.001,0.0001]\n",
        "        },\n",
        "        'optimizer':{\n",
        "            'values': ['Adam','SGD']\n",
        "        },\n",
        "        'data_aug': {\n",
        "            'values': ['No', 'Yes']\n",
        "        }\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project='DL A2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5AoQOnSN9LyE",
        "outputId": "7687ce5a-e75f-42e9-fbbb-6e71836929f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: doixdaf9 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: silu\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: No\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_aug: No\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_org: [32, 64, 64, 128, 128]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_size: [3, 3, 3, 3, 3]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_dense: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: SGD\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250413_100223-doixdaf9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL%20A2/runs/doixdaf9' target=\"_blank\">deft-sweep-3</a></strong> to <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL%20A2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL%20A2/sweeps/al6ebpim' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL%20A2/sweeps/al6ebpim</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL%20A2' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL%20A2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL%20A2/sweeps/al6ebpim' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL%20A2/sweeps/al6ebpim</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL%20A2/runs/doixdaf9' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL%20A2/runs/doixdaf9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-35-cc5c5e4323dd>\", line 23, in main\n",
            "    model_train_val(model=model_, train_data=train, val_data=validation, epochs = 100)\n",
            "  File \"<ipython-input-28-fbb3aa9b0fd8>\", line 8, in model_train_val\n",
            "    train_accuracy,avg_loss,model1 = training(model, train_data)\n",
            "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-34-2d0f18e92c85>\", line 18, in training\n",
            "    loss=loss_metric(output,label)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py\", line 1295, in forward\n",
            "    return F.cross_entropy(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\", line 3494, in cross_entropy\n",
            "    return torch._C._nn.cross_entropy_loss(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">ks[3, 3, 3, 3, 3]ac-silu_drop-0.3_fs-[32, 64, 64, 128, 128]_bn-No_dence-256</strong> at: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL%20A2/runs/doixdaf9' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL%20A2/runs/doixdaf9</a><br> View project at: <a href='https://wandb.ai/mfazal735-iit-madras-foundation/DL%20A2' target=\"_blank\">https://wandb.ai/mfazal735-iit-madras-foundation/DL%20A2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250413_100223-doixdaf9/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run doixdaf9 errored:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-35-cc5c5e4323dd>\", line 23, in main\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     model_train_val(model=model_, train_data=train, val_data=validation, epochs = 100)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-28-fbb3aa9b0fd8>\", line 8, in model_train_val\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     train_accuracy,avg_loss,model1 = training(model, train_data)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"<ipython-input-34-2d0f18e92c85>\", line 18, in training\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     loss=loss_metric(output,label)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py\", line 1295, in forward\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return F.cross_entropy(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\", line 3494, in cross_entropy\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return torch._C._nn.cross_entropy_loss(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument target in method wrapper_CUDA_nll_loss_forward)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "\n",
        "    with wandb.init() as run:\n",
        "        run_name=\"ks\"+str(wandb.config.kernel_size)+\"ac-\"+(wandb.config.activation)+\"_drop-\"+str(wandb.config.dropout)+\"_fs-\"+str(wandb.config.filter_org)+\"_bn-\"+str(wandb.config.batch_norm)+\"_dence-\"+str(wandb.config.num_dense)\n",
        "        wandb.run.name=run_name\n",
        "\n",
        "\n",
        "        if  wandb.config.activation == 'relu':\n",
        "            activ=nn.ReLU()\n",
        "        elif wandb.config.activation == 'gelu':\n",
        "            activ=nn.GELU()\n",
        "        elif wandb.config.activation == 'silu':\n",
        "            activ=nn.SiLU()\n",
        "        elif wandb.config.activation == 'mish':\n",
        "            activ=nn.Mish()\n",
        "\n",
        "        model_= model(num_filters=wandb.config.filter_org, filter_size=wandb.config.kernel_size,\n",
        "                      activation=activ, stride=1,padding=1, pool_size=(2,2), fc_size=wandb.config.num_dense,\n",
        "                      nom_o_classes=10,dropout = wandb.config.dropout).to(device)\n",
        "\n",
        "        train, validation = train_data(train_data_dir,data_augmentation= wandb.config.data_aug)\n",
        "\n",
        "        model_train_val(model=model_, train_data=train, val_data=validation, epochs = 100)\n",
        "\n",
        "wandb.agent(sweep_id, function= main,count= 10)\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "14EttBBjmZwg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1GhO8Nx22gW1t-cL9NZnp_rNiIURNdbqj",
      "authorship_tag": "ABX9TyNqr/vG1C4fcpPgHzCZNgWv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}